{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sb.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "virginica     50\n",
       "versicolor    50\n",
       "setosa        50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['species'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding Bias\n",
    "X['B']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  B\n",
       "0           5.1          3.5           1.4          0.2  1\n",
       "1           4.9          3.0           1.4          0.2  1\n",
       "2           4.7          3.2           1.3          0.2  1\n",
       "3           4.6          3.1           1.5          0.2  1\n",
       "4           5.0          3.6           1.4          0.2  1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(5,1,5),max_iter=1000000,random_state=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network (fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X,X)\n",
    "predictions = mlp.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    4.9\n",
       "sepal_width     3.0\n",
       "petal_length    1.4\n",
       "petal_width     0.2\n",
       "B               1.0\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.73999638, 3.07618225, 1.44303085, 0.17833639, 1.0004184 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(5, 5)\n",
      "(5, 1)\n",
      "(1, 5)\n",
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "print(len(mlp.coefs_))\n",
    "for i in mlp.coefs_:\n",
    "    print (i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = X.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 3.5, 1.4, 0.2, 1. ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04833450882104276"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = sigmoid(np.dot(samp,mlp.coefs_[0])+mlp.intercepts_[0])\n",
    "l2 = sigmoid(np.dot(l1,mlp.coefs_[1])+mlp.intercepts_[1])\n",
    "l2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04833451])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.09380016, 3.54710521, 1.45595706, 0.2490054 , 1.00031323])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3 = sigmoid(np.dot(l2,mlp.coefs_[2])+mlp.intercepts_[2])\n",
    "l4 = np.dot(l3,mlp.coefs_[3])+mlp.intercepts_[3]\n",
    "l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(mlp,samp):\n",
    "    l1 = sigmoid(np.dot(samp,mlp.coefs_[0])+mlp.intercepts_[0])\n",
    "    l2 = sigmoid(np.dot(l1,mlp.coefs_[1])+mlp.intercepts_[1])\n",
    "    return l2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cls']=0\n",
    "for k,v in df.iterrows():\n",
    "    df.loc[k,'cls'] = encode(mlp,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0.048335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0.077885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0.071790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0.081436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0.046654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species       cls\n",
       "0           5.1          3.5           1.4          0.2  setosa  0.048335\n",
       "1           4.9          3.0           1.4          0.2  setosa  0.077885\n",
       "2           4.7          3.2           1.3          0.2  setosa  0.071790\n",
       "3           4.6          3.1           1.5          0.2  setosa  0.081436\n",
       "4           5.0          3.6           1.4          0.2  setosa  0.046654"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>5.006</td>\n",
       "      <td>3.428</td>\n",
       "      <td>1.462</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.056892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>5.936</td>\n",
       "      <td>2.770</td>\n",
       "      <td>4.260</td>\n",
       "      <td>1.326</td>\n",
       "      <td>0.358990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>6.588</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.552</td>\n",
       "      <td>2.026</td>\n",
       "      <td>0.508146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sepal_length  sepal_width  petal_length  petal_width       cls\n",
       "species                                                                   \n",
       "setosa             5.006        3.428         1.462        0.246  0.056892\n",
       "versicolor         5.936        2.770         4.260        1.326  0.358990\n",
       "virginica          6.588        2.974         5.552        2.026  0.508146"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('species').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.338837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.383173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.337256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.282937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.341252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.346670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.350336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.368626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.277104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>0.344637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.534835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.397121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.585842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.460979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.515593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.744849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.339401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.650159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.508755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "      <td>0.637832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species  \\\n",
       "90            5.5          2.6           4.4          1.2  versicolor   \n",
       "91            6.1          3.0           4.6          1.4  versicolor   \n",
       "92            5.8          2.6           4.0          1.2  versicolor   \n",
       "93            5.0          2.3           3.3          1.0  versicolor   \n",
       "94            5.6          2.7           4.2          1.3  versicolor   \n",
       "95            5.7          3.0           4.2          1.2  versicolor   \n",
       "96            5.7          2.9           4.2          1.3  versicolor   \n",
       "97            6.2          2.9           4.3          1.3  versicolor   \n",
       "98            5.1          2.5           3.0          1.1  versicolor   \n",
       "99            5.7          2.8           4.1          1.3  versicolor   \n",
       "100           6.3          3.3           6.0          2.5   virginica   \n",
       "101           5.8          2.7           5.1          1.9   virginica   \n",
       "102           7.1          3.0           5.9          2.1   virginica   \n",
       "103           6.3          2.9           5.6          1.8   virginica   \n",
       "104           6.5          3.0           5.8          2.2   virginica   \n",
       "105           7.6          3.0           6.6          2.1   virginica   \n",
       "106           4.9          2.5           4.5          1.7   virginica   \n",
       "107           7.3          2.9           6.3          1.8   virginica   \n",
       "108           6.7          2.5           5.8          1.8   virginica   \n",
       "109           7.2          3.6           6.1          2.5   virginica   \n",
       "\n",
       "          cls  \n",
       "90   0.338837  \n",
       "91   0.383173  \n",
       "92   0.337256  \n",
       "93   0.282937  \n",
       "94   0.341252  \n",
       "95   0.346670  \n",
       "96   0.350336  \n",
       "97   0.368626  \n",
       "98   0.277104  \n",
       "99   0.344637  \n",
       "100  0.534835  \n",
       "101  0.397121  \n",
       "102  0.585842  \n",
       "103  0.460979  \n",
       "104  0.515593  \n",
       "105  0.744849  \n",
       "106  0.339401  \n",
       "107  0.650159  \n",
       "108  0.508755  \n",
       "109  0.637832  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[90:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# calculate mse of predictions (output of the NN) vs. X for:\n",
    "# (2,1,2)\n",
    "# (5,1,5)\n",
    "# (10,1,10)\n",
    "# (15,1,15)\n",
    "# (20,1,20)\n",
    "# (25,1,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  B\n",
       "0             5.1          3.5           1.4          0.2  1\n",
       "1             4.9          3.0           1.4          0.2  1\n",
       "2             4.7          3.2           1.3          0.2  1\n",
       "3             4.6          3.1           1.5          0.2  1\n",
       "4             5.0          3.6           1.4          0.2  1\n",
       "..            ...          ...           ...          ... ..\n",
       "145           6.7          3.0           5.2          2.3  1\n",
       "146           6.3          2.5           5.0          1.9  1\n",
       "147           6.5          3.0           5.2          2.0  1\n",
       "148           6.2          3.4           5.4          2.3  1\n",
       "149           5.9          3.0           5.1          1.8  1\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_ = X.iloc[:, :4].values\n",
    "X_[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.09380016, 3.54710521, 1.45595706, 0.2490054 ],\n",
       "       [4.73999638, 3.07618225, 1.44303085, 0.17833639],\n",
       "       [4.8038786 , 3.16422415, 1.44059487, 0.18934358]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ = predictions[:, :4]\n",
    "pred_[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00619984, -0.04710521, -0.05595706, -0.0490054 ],\n",
       "       [ 0.16000362, -0.07618225, -0.04303085,  0.02166361],\n",
       "       [-0.1038786 ,  0.03577585, -0.14059487,  0.01065642]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ = (X_ - pred_)\n",
    "d_[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.84380126e-05, 2.21890107e-03, 3.13119274e-03, 2.40152889e-03],\n",
       "       [2.56011571e-02, 5.80373454e-03, 1.85165411e-03, 4.69311804e-04],\n",
       "       [1.07907626e-02, 1.27991158e-03, 1.97669167e-02, 1.13559353e-04]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ = d_**2\n",
    "d_[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00194752, 0.00843146, 0.00798779, 0.00500634])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_ = np.mean(d_, axis=1)\n",
    "m_[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04353270138528518"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_ = np.mean(m_)\n",
    "err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Square Error (MSE): 0.2066\n"
     ]
    }
   ],
   "source": [
    "mlp1 = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(2,1,2),max_iter=1000000,random_state=111)\n",
    "mlp1.fit(X,X)\n",
    "pred1 = mlp1.predict(X)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse1 = mean_squared_error(pred1, X)\n",
    "print('Mean-Square Error (MSE): %.4f' % lin_mse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Square Error (MSE): 0.0348\n"
     ]
    }
   ],
   "source": [
    "mlp2 = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(5,1,5),max_iter=1000000,random_state=111)\n",
    "mlp2.fit(X,X)\n",
    "pred2 = mlp2.predict(X)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse2 = mean_squared_error(pred2, X)\n",
    "print('Mean-Square Error (MSE): %.4f' % lin_mse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Square Error (MSE): 0.0510\n"
     ]
    }
   ],
   "source": [
    "mlp3 = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(10,1,10),max_iter=1000000,random_state=111)\n",
    "mlp3.fit(X,X)\n",
    "pred3 = mlp3.predict(X)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse3 = mean_squared_error(pred3, X)\n",
    "print('Mean-Square Error (MSE): %.4f' % lin_mse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Square Error (MSE): 0.0345\n"
     ]
    }
   ],
   "source": [
    "mlp4 = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(15,1,15),max_iter=1000000,random_state=111)\n",
    "mlp4.fit(X,X)\n",
    "pred4 = mlp4.predict(X)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse4 = mean_squared_error(pred4, X)\n",
    "print('Mean-Square Error (MSE): %.4f' % lin_mse4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Square Error (MSE): 0.0511\n"
     ]
    }
   ],
   "source": [
    "mlp5 = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(20,1,20),max_iter=1000000,random_state=111)\n",
    "mlp5.fit(X,X)\n",
    "pred5 = mlp5.predict(X)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse5 = mean_squared_error(pred5, X)\n",
    "print('Mean-Square Error (MSE): %.4f' % lin_mse5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-Square Error (MSE): 0.0508\n"
     ]
    }
   ],
   "source": [
    "mlp6 = MLPRegressor(solver='lbfgs',activation='logistic',learning_rate_init=0.00001, alpha=1e-5, \n",
    "                   hidden_layer_sizes=(25,1,25),max_iter=1000000,random_state=111)\n",
    "mlp6.fit(X,X)\n",
    "pred6 = mlp6.predict(X)\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse6 = mean_squared_error(pred6, X)\n",
    "print('Mean-Square Error (MSE): %.4f' % lin_mse6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# feature reduction (4->1)\n",
    "# print confusion matrix and accuracy score using 4 feature (original and using 1 feature (cls)).\n",
    "#      split to 33% test, seed = 47\n",
    "#      use RF() and LogReg()\n",
    "#      try for all the five NN architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LogReg() and RF() using 4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df.loc[:, df.columns != 'species']\n",
    "y = df.loc[:, df.columns == 'species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.where(y =='setosa', 0, y)\n",
    "y=np.where(y =='versicolor', 1, y)\n",
    "y=np.where(y =='virginica', 2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)\n",
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_4: 0.9800\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  1 20]]\n",
      "Accuracy of Random Forest classifier on test set y_gb_4: 0.9600\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  2 19]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_4 = logreg.predict(X_test)\n",
    "acc_log_4 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_4: {:.4f}'.format(acc_log_4))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_4)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_4 = rf.predict(X_test)\n",
    "acc_rf_4 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_gb_4: {:.4f}'.format(acc_rf_4))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_4)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LogReg() and RF() using 1 feature (cls) (2,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = df.drop(['species'],axis=1)\n",
    "X3['B']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3['cls1']=0\n",
    "for k,v in X2.iterrows():\n",
    "    X3.loc[k,'cls1'] = encode(mlp1,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))\n",
    "X3['cls2']=0\n",
    "for k,v in X2.iterrows():\n",
    "    X3.loc[k,'cls2'] = encode(mlp2,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))\n",
    "X3['cls3']=0\n",
    "for k,v in X2.iterrows():\n",
    "    X3.loc[k,'cls3'] = encode(mlp3,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))\n",
    "X3['cls4']=0\n",
    "for k,v in X2.iterrows():\n",
    "    X3.loc[k,'cls4'] = encode(mlp4,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))\n",
    "X3['cls5']=0\n",
    "for k,v in X2.iterrows():\n",
    "    X3.loc[k,'cls5'] = encode(mlp5,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))\n",
    "X3['cls6']=0\n",
    "for k,v in X2.iterrows():\n",
    "    X3.loc[k,'cls6'] = encode(mlp6,np.array([v.sepal_length , v.sepal_width,v.petal_length,v.petal_width,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>cls</th>\n",
       "      <th>B</th>\n",
       "      <th>cls1</th>\n",
       "      <th>cls2</th>\n",
       "      <th>cls3</th>\n",
       "      <th>cls4</th>\n",
       "      <th>cls5</th>\n",
       "      <th>cls6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.048335</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.048335</td>\n",
       "      <td>6.293450e-09</td>\n",
       "      <td>0.080788</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>9.440770e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>6.325430e-09</td>\n",
       "      <td>0.107492</td>\n",
       "      <td>0.017227</td>\n",
       "      <td>2.073627e-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.071790</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.071790</td>\n",
       "      <td>5.875674e-09</td>\n",
       "      <td>0.106785</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>7.082877e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.081436</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.081436</td>\n",
       "      <td>6.344351e-09</td>\n",
       "      <td>0.113787</td>\n",
       "      <td>0.015906</td>\n",
       "      <td>2.559366e-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.046654</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.046654</td>\n",
       "      <td>6.195255e-09</td>\n",
       "      <td>0.081248</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>6.977517e-34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width       cls  B  \\\n",
       "0           5.1          3.5           1.4          0.2  0.048335  1   \n",
       "1           4.9          3.0           1.4          0.2  0.077885  1   \n",
       "2           4.7          3.2           1.3          0.2  0.071790  1   \n",
       "3           4.6          3.1           1.5          0.2  0.081436  1   \n",
       "4           5.0          3.6           1.4          0.2  0.046654  1   \n",
       "\n",
       "       cls1      cls2          cls3      cls4      cls5          cls6  \n",
       "0  0.000021  0.048335  6.293450e-09  0.080788  0.006858  9.440770e-34  \n",
       "1  0.000021  0.077885  6.325430e-09  0.107492  0.017227  2.073627e-33  \n",
       "2  0.000021  0.071790  5.875674e-09  0.106785  0.003707  7.082877e-34  \n",
       "3  0.000021  0.081436  6.344351e-09  0.113787  0.015906  2.559366e-33  \n",
       "4  0.000021  0.046654  6.195255e-09  0.081248  0.003641  6.977517e-34  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_11: 0.5800\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0 21  0]]\n",
      "Accuracy of Random Forest classifier on test set y_rf_11: 0.5800\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0 21  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "X4 = X3.loc[:, X3.columns == 'cls1']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_11 = logreg.predict(X_test)\n",
    "acc_log_11 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_11: {:.4f}'.format(acc_log_11))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_11)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_11 = rf.predict(X_test)\n",
    "acc_rf_11 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_rf_11: {:.4f}'.format(acc_rf_11))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_11)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LogReg() and RF() using 1 feature (cls) (5,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_12: 0.7400\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0 13  8]]\n",
      "Accuracy of Random Forest classifier on test set y_rf_12: 0.9200\n",
      "[[20  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  3 18]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "X5 = X3.loc[:, X3.columns == 'cls2']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X5, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_12 = logreg.predict(X_test)\n",
    "acc_log_12 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_12: {:.4f}'.format(acc_log_12))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_12)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_12 = rf.predict(X_test)\n",
    "acc_rf_12 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_rf_12: {:.4f}'.format(acc_rf_12))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_12)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LogReg() and RF() using 1 feature (cls) (10,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_13: 0.5800\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0 21  0]]\n",
      "Accuracy of Random Forest classifier on test set y_rf_13: 0.8800\n",
      "[[20  0  0]\n",
      " [ 0  7  2]\n",
      " [ 0  4 17]]\n"
     ]
    }
   ],
   "source": [
    "X6 = X3.loc[:, X3.columns == 'cls3']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X6, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_13 = logreg.predict(X_test)\n",
    "acc_log_13 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_13: {:.4f}'.format(acc_log_13))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_13)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_13 = rf.predict(X_test)\n",
    "acc_rf_13 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_rf_13: {:.4f}'.format(acc_rf_13))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_13)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LogReg() and RF() using 1 feature (cls) (15,1,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_14: 0.5800\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0 21  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest classifier on test set y_rf_14: 0.8600\n",
      "[[20  0  0]\n",
      " [ 0  6  3]\n",
      " [ 0  4 17]]\n"
     ]
    }
   ],
   "source": [
    "X7 = X3.loc[:, X3.columns == 'cls4']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X7, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_14 = logreg.predict(X_test)\n",
    "acc_log_14 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_14: {:.4f}'.format(acc_log_14))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_14)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_14 = rf.predict(X_test)\n",
    "acc_rf_14 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_rf_14: {:.4f}'.format(acc_rf_14))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_14)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LogReg() and RF() using 1 feature (cls) (20,1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_15: 0.8000\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0 10 11]]\n",
      "Accuracy of Random Forest classifier on test set y_rf_15: 0.9000\n",
      "[[20  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  4 17]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "X8 = X3.loc[:, X3.columns == 'cls5']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X8, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_15 = logreg.predict(X_test)\n",
    "acc_log_15 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_15: {:.4f}'.format(acc_log_15))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_15)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_15 = rf.predict(X_test)\n",
    "acc_rf_15 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_rf_15: {:.4f}'.format(acc_rf_15))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_15)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LogReg() and RF() using 1 feature (cls) (25,1,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on test set y_log_16: 0.8400\n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  8 13]]\n",
      "Accuracy of Random Forest classifier on test set y_rf_16: 0.9000\n",
      "[[20  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  4 17]]\n"
     ]
    }
   ],
   "source": [
    "X9 = X3.loc[:, X3.columns == 'cls6']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X9, y, test_size=0.33, random_state=47)\n",
    "logreg = LogisticRegression(random_state=47)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_log_16 = logreg.predict(X_test)\n",
    "acc_log_16 = logreg.score(X_test, y_test)\n",
    "print('Accuracy of Logistic Regression classifier on test set y_log_16: {:.4f}'.format(acc_log_16))\n",
    "confusion_matrix1 = confusion_matrix(y_test, y_log_16)\n",
    "print(confusion_matrix1)\n",
    "rf = RandomForestClassifier(random_state=47)\n",
    "rf.fit(X_train, y_train)\n",
    "y_rf_16 = rf.predict(X_test)\n",
    "acc_rf_16 = rf.score(X_test, y_test)\n",
    "print('Accuracy of Random Forest classifier on test set y_rf_16: {:.4f}'.format(acc_rf_16))\n",
    "confusion_matrix2 = confusion_matrix(y_test, y_rf_16)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['4 features LoReg','4 features RF','cls(2,1,2) LoReg', 'cls(2,1,2) RF',\n",
    "          'cls(5,1,5) LoReg', 'cls(5,1,5) RF', 'cls(10,1,10) LoReg', 'cls(10,1,10) RF',\n",
    "          'cls(15,1,15) LoReg', 'cls(15,1,15) RF','cls(20,1,20) LoReg', 'cls(20,1,20) RF',\n",
    "          'cls(25,1,25) LoReg', 'cls(25,1,25) RF']\n",
    "tests_accuracy = [acc_log_4, acc_rf_4, acc_log_11, acc_rf_11, \n",
    "                  acc_log_12, acc_rf_12, acc_log_13, acc_rf_13,\n",
    "                  acc_log_14, acc_rf_14, acc_log_15, acc_rf_15, \n",
    "                  acc_log_13, acc_rf_16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithms</th>\n",
       "      <th>Tests Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 features LoReg</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 features RF</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cls(5,1,5) RF</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cls(20,1,20) RF</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cls(25,1,25) RF</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cls(10,1,10) RF</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cls(15,1,15) RF</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cls(20,1,20) LoReg</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cls(5,1,5) LoReg</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cls(2,1,2) LoReg</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cls(2,1,2) RF</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cls(10,1,10) LoReg</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cls(15,1,15) LoReg</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cls(25,1,25) LoReg</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Algorithms  Tests Accuracy\n",
       "0     4 features LoReg            0.98\n",
       "1        4 features RF            0.96\n",
       "5        cls(5,1,5) RF            0.92\n",
       "11     cls(20,1,20) RF            0.90\n",
       "13     cls(25,1,25) RF            0.90\n",
       "7      cls(10,1,10) RF            0.88\n",
       "9      cls(15,1,15) RF            0.86\n",
       "10  cls(20,1,20) LoReg            0.80\n",
       "4     cls(5,1,5) LoReg            0.74\n",
       "2     cls(2,1,2) LoReg            0.58\n",
       "3        cls(2,1,2) RF            0.58\n",
       "6   cls(10,1,10) LoReg            0.58\n",
       "8   cls(15,1,15) LoReg            0.58\n",
       "12  cls(25,1,25) LoReg            0.58"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models = pd.DataFrame({ \"Algorithms\": models, \"Tests Accuracy\": tests_accuracy })\n",
    "compare_models.sort_values(by = \"Tests Accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.barplot(x = \"Tests Accuracy\", y = \"Algorithms\", data = compare_models)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 4 features Random Forest Classifier wins it all here with a maximum accuracy of 0.98."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
